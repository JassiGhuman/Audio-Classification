{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SINCNET_audio_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Sincnet Implementaion\n",
        "We tried to implement SINCNET for audio classification. \n",
        "Code is refered from https://github.com/mravanelli/SincNet"
      ],
      "metadata": {
        "id": "BfZKZMfa23I2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EeOSyMAO2QGX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import sys\n",
        "from torch.autograd import Variable\n",
        "import math\n",
        "\n",
        "def flip(x, dim):\n",
        "    xsize = x.size()\n",
        "    dim = x.dim() + dim if dim < 0 else dim\n",
        "    x = x.contiguous()\n",
        "    x = x.view(-1, *xsize[dim:])\n",
        "    x = x.view(x.size(0), x.size(1), -1)[:, getattr(torch.arange(x.size(1)-1, \n",
        "                      -1, -1), ('cpu','cuda')[x.is_cuda])().long(), :]\n",
        "    return x.view(xsize)\n",
        "\n",
        "\n",
        "def sinc(band,t_right):\n",
        "    y_right= torch.sin(2*math.pi*band*t_right)/(2*math.pi*band*t_right)\n",
        "    y_left= flip(y_right,0)\n",
        "\n",
        "    y=torch.cat([y_left,Variable(torch.ones(1)).cuda(),y_right])\n",
        "\n",
        "    return y\n",
        "    \n",
        "\n",
        "class SincConv_fast(nn.Module):\n",
        "    \"\"\"Sinc-based convolution\n",
        "    Parameters\n",
        "    ----------\n",
        "    in_channels : `int`\n",
        "        Number of input channels. Must be 1.\n",
        "    out_channels : `int`\n",
        "        Number of filters.\n",
        "    kernel_size : `int`\n",
        "        Filter length.\n",
        "    sample_rate : `int`, optional\n",
        "        Sample rate. Defaults to 16000.\n",
        "    Usage\n",
        "    -----\n",
        "    See `torch.nn.Conv1d`\n",
        "    Reference\n",
        "    ---------\n",
        "    Mirco Ravanelli, Yoshua Bengio,\n",
        "    \"Speaker Recognition from raw waveform with SincNet\".\n",
        "    https://arxiv.org/abs/1808.00158\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def to_mel(hz):\n",
        "        return 2595 * np.log10(1 + hz / 700)\n",
        "\n",
        "    @staticmethod\n",
        "    def to_hz(mel):\n",
        "        return 700 * (10 ** (mel / 2595) - 1)\n",
        "\n",
        "    def __init__(self, out_channels, kernel_size, sample_rate=16000, in_channels=1,\n",
        "                 stride=1, padding=0, dilation=1, bias=False, groups=1, min_low_hz=50, min_band_hz=50):\n",
        "\n",
        "        super(SincConv_fast,self).__init__()\n",
        "\n",
        "        if in_channels != 1:\n",
        "            #msg = (f'SincConv only support one input channel '\n",
        "            #       f'(here, in_channels = {in_channels:d}).')\n",
        "            msg = \"SincConv only support one input channel (here, in_channels = {%i})\" % (in_channels)\n",
        "            raise ValueError(msg)\n",
        "\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        \n",
        "        # Forcing the filters to be odd (i.e, perfectly symmetrics)\n",
        "        if kernel_size%2==0:\n",
        "            self.kernel_size=self.kernel_size+1\n",
        "            \n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.dilation = dilation\n",
        "\n",
        "        if bias:\n",
        "            raise ValueError('SincConv does not support bias.')\n",
        "        if groups > 1:\n",
        "            raise ValueError('SincConv does not support groups.')\n",
        "\n",
        "        self.sample_rate = sample_rate\n",
        "        self.min_low_hz = min_low_hz\n",
        "        self.min_band_hz = min_band_hz\n",
        "\n",
        "        # initialize filterbanks such that they are equally spaced in Mel scale\n",
        "        low_hz = 30\n",
        "        high_hz = self.sample_rate / 2 - (self.min_low_hz + self.min_band_hz)\n",
        "\n",
        "        mel = np.linspace(self.to_mel(low_hz),\n",
        "                          self.to_mel(high_hz),\n",
        "                          self.out_channels + 1)\n",
        "        hz = self.to_hz(mel)\n",
        "        \n",
        "\n",
        "        # filter lower frequency (out_channels, 1)\n",
        "        self.low_hz_ = nn.Parameter(torch.Tensor(hz[:-1]).view(-1, 1))\n",
        "\n",
        "        # filter frequency band (out_channels, 1)\n",
        "        self.band_hz_ = nn.Parameter(torch.Tensor(np.diff(hz)).view(-1, 1))\n",
        "\n",
        "        # Hamming window\n",
        "        #self.window_ = torch.hamming_window(self.kernel_size)\n",
        "        n_lin=torch.linspace(0, (self.kernel_size/2)-1, steps=int((self.kernel_size/2))) # computing only half of the window\n",
        "        self.window_=0.54-0.46*torch.cos(2*math.pi*n_lin/self.kernel_size);\n",
        "\n",
        "\n",
        "        # (1, kernel_size/2)\n",
        "        n = (self.kernel_size - 1) / 2.0\n",
        "        self.n_ = 2*math.pi*torch.arange(-n, 0).view(1, -1) / self.sample_rate # Due to symmetry, I only need half of the time axes\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "    def forward(self, waveforms):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        waveforms : `torch.Tensor` (batch_size, 1, n_samples)\n",
        "            Batch of waveforms.\n",
        "        Returns\n",
        "        -------\n",
        "        features : `torch.Tensor` (batch_size, out_channels, n_samples_out)\n",
        "            Batch of sinc filters activations.\n",
        "        \"\"\"\n",
        "\n",
        "        self.n_ = self.n_.to(waveforms.device)\n",
        "\n",
        "        self.window_ = self.window_.to(waveforms.device)\n",
        "\n",
        "        low = self.min_low_hz  + torch.abs(self.low_hz_)\n",
        "        \n",
        "        high = torch.clamp(low + self.min_band_hz + torch.abs(self.band_hz_),self.min_low_hz,self.sample_rate/2)\n",
        "        band=(high-low)[:,0]\n",
        "        \n",
        "        f_times_t_low = torch.matmul(low, self.n_)\n",
        "        f_times_t_high = torch.matmul(high, self.n_)\n",
        "\n",
        "        band_pass_left=((torch.sin(f_times_t_high)-torch.sin(f_times_t_low))/(self.n_/2))*self.window_ # Equivalent of Eq.4 of the reference paper (SPEAKER RECOGNITION FROM RAW WAVEFORM WITH SINCNET). I just have expanded the sinc and simplified the terms. This way I avoid several useless computations. \n",
        "        band_pass_center = 2*band.view(-1,1)\n",
        "        band_pass_right= torch.flip(band_pass_left,dims=[1])\n",
        "        \n",
        "        \n",
        "        band_pass=torch.cat([band_pass_left,band_pass_center,band_pass_right],dim=1)\n",
        "\n",
        "        \n",
        "        band_pass = band_pass / (2*band[:,None])\n",
        "        \n",
        "\n",
        "        self.filters = (band_pass).view(\n",
        "            self.out_channels, 1, self.kernel_size)\n",
        "\n",
        "        return F.conv1d(waveforms, self.filters, stride=self.stride,\n",
        "                        padding=self.padding, dilation=self.dilation,\n",
        "                         bias=None, groups=1) \n",
        "\n",
        "\n",
        "        \n",
        "        \n",
        "class sinc_conv(nn.Module):\n",
        "\n",
        "    def __init__(self, N_filt,Filt_dim,fs):\n",
        "        super(sinc_conv,self).__init__()\n",
        "\n",
        "        # Mel Initialization of the filterbanks\n",
        "        low_freq_mel = 80\n",
        "        high_freq_mel = (2595 * np.log10(1 + (fs / 2) / 700))  # Convert Hz to Mel\n",
        "        mel_points = np.linspace(low_freq_mel, high_freq_mel, N_filt)  # Equally spaced in Mel scale\n",
        "        f_cos = (700 * (10**(mel_points / 2595) - 1)) # Convert Mel to Hz\n",
        "        b1=np.roll(f_cos,1)\n",
        "        b2=np.roll(f_cos,-1)\n",
        "        b1[0]=30\n",
        "        b2[-1]=(fs/2)-100\n",
        "                \n",
        "        self.freq_scale=fs*1.0\n",
        "        self.filt_b1 = nn.Parameter(torch.from_numpy(b1/self.freq_scale))\n",
        "        self.filt_band = nn.Parameter(torch.from_numpy((b2-b1)/self.freq_scale))\n",
        "\n",
        "        \n",
        "        self.N_filt=N_filt\n",
        "        self.Filt_dim=Filt_dim\n",
        "        self.fs=fs\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        filters=Variable(torch.zeros((self.N_filt,self.Filt_dim))).cuda()\n",
        "        N=self.Filt_dim\n",
        "        t_right=Variable(torch.linspace(1, (N-1)/2, steps=int((N-1)/2))/self.fs).cuda()\n",
        "        \n",
        "        \n",
        "        min_freq=50.0;\n",
        "        min_band=50.0;\n",
        "        \n",
        "        filt_beg_freq=torch.abs(self.filt_b1)+min_freq/self.freq_scale\n",
        "        filt_end_freq=filt_beg_freq+(torch.abs(self.filt_band)+min_band/self.freq_scale)\n",
        "       \n",
        "        n=torch.linspace(0, N, steps=N)\n",
        "\n",
        "        # Filter window (hamming)\n",
        "        window=0.54-0.46*torch.cos(2*math.pi*n/N);\n",
        "        window=Variable(window.float().cuda())\n",
        "\n",
        "        \n",
        "        for i in range(self.N_filt):\n",
        "                        \n",
        "            low_pass1 = 2*filt_beg_freq[i].float()*sinc(filt_beg_freq[i].float()*self.freq_scale,t_right)\n",
        "            low_pass2 = 2*filt_end_freq[i].float()*sinc(filt_end_freq[i].float()*self.freq_scale,t_right)\n",
        "            band_pass=(low_pass2-low_pass1)\n",
        "\n",
        "            band_pass=band_pass/torch.max(band_pass)\n",
        "\n",
        "            filters[i,:]=band_pass.cuda()*window\n",
        "\n",
        "        out=F.conv1d(x, filters.view(self.N_filt,1,self.Filt_dim))\n",
        "    \n",
        "        return out\n",
        "    \n",
        "\n",
        "def act_fun(act_type):\n",
        "\n",
        " if act_type==\"relu\":\n",
        "    return nn.ReLU()\n",
        "            \n",
        " if act_type==\"tanh\":\n",
        "    return nn.Tanh()\n",
        "            \n",
        " if act_type==\"sigmoid\":\n",
        "    return nn.Sigmoid()\n",
        "           \n",
        " if act_type==\"leaky_relu\":\n",
        "    return nn.LeakyReLU(0.2)\n",
        "            \n",
        " if act_type==\"elu\":\n",
        "    return nn.ELU()\n",
        "                     \n",
        " if act_type==\"softmax\":\n",
        "    return nn.LogSoftmax(dim=1)\n",
        "        \n",
        " if act_type==\"linear\":\n",
        "    return nn.LeakyReLU(1) # initializzed like this, but not used in forward!\n",
        "            \n",
        "            \n",
        "class LayerNorm(nn.Module):\n",
        "\n",
        "    def __init__(self, features, eps=1e-6):\n",
        "        super(LayerNorm,self).__init__()\n",
        "        self.gamma = nn.Parameter(torch.ones(features))\n",
        "        self.beta = nn.Parameter(torch.zeros(features))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, options):\n",
        "        super(MLP, self).__init__()\n",
        "        \n",
        "        self.input_dim=int(options['input_dim'])\n",
        "        self.fc_lay=options['fc_lay']\n",
        "        self.fc_drop=options['fc_drop']\n",
        "        self.fc_use_batchnorm=options['fc_use_batchnorm']\n",
        "        self.fc_use_laynorm=options['fc_use_laynorm']\n",
        "        self.fc_use_laynorm_inp=options['fc_use_laynorm_inp']\n",
        "        self.fc_use_batchnorm_inp=options['fc_use_batchnorm_inp']\n",
        "        self.fc_act=options['fc_act']\n",
        "        \n",
        "       \n",
        "        self.wx  = nn.ModuleList([])\n",
        "        self.bn  = nn.ModuleList([])\n",
        "        self.ln  = nn.ModuleList([])\n",
        "        self.act = nn.ModuleList([])\n",
        "        self.drop = nn.ModuleList([])\n",
        "       \n",
        "\n",
        "       \n",
        "        # input layer normalization\n",
        "        if self.fc_use_laynorm_inp:\n",
        "           self.ln0=LayerNorm(self.input_dim)\n",
        "          \n",
        "        # input batch normalization    \n",
        "        if self.fc_use_batchnorm_inp:\n",
        "           self.bn0=nn.BatchNorm1d([self.input_dim],momentum=0.05)\n",
        "           \n",
        "           \n",
        "        self.N_fc_lay=len(self.fc_lay)\n",
        "             \n",
        "        current_input=self.input_dim\n",
        "        \n",
        "        # Initialization of hidden layers\n",
        "        \n",
        "        for i in range(self.N_fc_lay):\n",
        "            \n",
        "         # dropout\n",
        "         self.drop.append(nn.Dropout(p=self.fc_drop[i]))\n",
        "         \n",
        "         # activation\n",
        "         self.act.append(act_fun(self.fc_act[i]))\n",
        "         \n",
        "         \n",
        "         add_bias=True\n",
        "         \n",
        "         # layer norm initialization\n",
        "         self.ln.append(LayerNorm(self.fc_lay[i]))\n",
        "         self.bn.append(nn.BatchNorm1d(self.fc_lay[i],momentum=0.05))\n",
        "         \n",
        "         if self.fc_use_laynorm[i] or self.fc_use_batchnorm[i]:\n",
        "             add_bias=False\n",
        "         \n",
        "              \n",
        "         # Linear operations\n",
        "         self.wx.append(nn.Linear(current_input, self.fc_lay[i],bias=add_bias))\n",
        "         \n",
        "         # weight initialization\n",
        "         self.wx[i].weight = torch.nn.Parameter(torch.Tensor(self.fc_lay[i],current_input).uniform_(-np.sqrt(0.01/(current_input+self.fc_lay[i])),np.sqrt(0.01/(current_input+self.fc_lay[i]))))\n",
        "         self.wx[i].bias = torch.nn.Parameter(torch.zeros(self.fc_lay[i]))\n",
        "         \n",
        "         current_input=self.fc_lay[i]\n",
        "         \n",
        "         \n",
        "    def forward(self, x):\n",
        "        \n",
        "      # Applying Layer/Batch Norm\n",
        "      if bool(self.fc_use_laynorm_inp):\n",
        "        x=self.ln0((x))\n",
        "        \n",
        "      if bool(self.fc_use_batchnorm_inp):\n",
        "        x=self.bn0((x))\n",
        "        \n",
        "      for i in range(self.N_fc_lay):\n",
        "\n",
        "        if self.fc_act[i]!='linear':\n",
        "            \n",
        "          if self.fc_use_laynorm[i]:\n",
        "           x = self.drop[i](self.act[i](self.ln[i](self.wx[i](x))))\n",
        "          \n",
        "          if self.fc_use_batchnorm[i]:\n",
        "           x = self.drop[i](self.act[i](self.bn[i](self.wx[i](x))))\n",
        "          \n",
        "          if self.fc_use_batchnorm[i]==False and self.fc_use_laynorm[i]==False:\n",
        "           x = self.drop[i](self.act[i](self.wx[i](x)))\n",
        "           \n",
        "        else:\n",
        "          if self.fc_use_laynorm[i]:\n",
        "           x = self.drop[i](self.ln[i](self.wx[i](x)))\n",
        "          \n",
        "          if self.fc_use_batchnorm[i]:\n",
        "           x = self.drop[i](self.bn[i](self.wx[i](x)))\n",
        "          \n",
        "          if self.fc_use_batchnorm[i]==False and self.fc_use_laynorm[i]==False:\n",
        "           x = self.drop[i](self.wx[i](x)) \n",
        "          \n",
        "      return x\n",
        "\n",
        "\n",
        "\n",
        "class SincNet(nn.Module):\n",
        "    \n",
        "    def __init__(self,options):\n",
        "       super(SincNet,self).__init__()\n",
        "    \n",
        "       self.cnn_N_filt=options['cnn_N_filt']\n",
        "       self.cnn_len_filt=options['cnn_len_filt']\n",
        "       self.cnn_max_pool_len=options['cnn_max_pool_len']\n",
        "       \n",
        "       \n",
        "       self.cnn_act=options['cnn_act']\n",
        "       self.cnn_drop=options['cnn_drop']\n",
        "       \n",
        "       self.cnn_use_laynorm=options['cnn_use_laynorm']\n",
        "       self.cnn_use_batchnorm=options['cnn_use_batchnorm']\n",
        "       self.cnn_use_laynorm_inp=options['cnn_use_laynorm_inp']\n",
        "       self.cnn_use_batchnorm_inp=options['cnn_use_batchnorm_inp']\n",
        "       \n",
        "       self.input_dim=int(options['input_dim'])\n",
        "       \n",
        "       self.fs=options['fs']\n",
        "       \n",
        "       self.N_cnn_lay=len(options['cnn_N_filt'])\n",
        "       self.conv  = nn.ModuleList([])\n",
        "       self.bn  = nn.ModuleList([])\n",
        "       self.ln  = nn.ModuleList([])\n",
        "       self.act = nn.ModuleList([])\n",
        "       self.drop = nn.ModuleList([])\n",
        "       \n",
        "             \n",
        "       if self.cnn_use_laynorm_inp:\n",
        "           self.ln0=LayerNorm(self.input_dim)\n",
        "           \n",
        "       if self.cnn_use_batchnorm_inp:\n",
        "           self.bn0=nn.BatchNorm1d([self.input_dim],momentum=0.05)\n",
        "           \n",
        "       current_input=self.input_dim \n",
        "       \n",
        "       for i in range(self.N_cnn_lay):\n",
        "         \n",
        "         N_filt=int(self.cnn_N_filt[i])\n",
        "         len_filt=int(self.cnn_len_filt[i])\n",
        "         \n",
        "         # dropout\n",
        "         self.drop.append(nn.Dropout(p=self.cnn_drop[i]))\n",
        "         \n",
        "         # activation\n",
        "         self.act.append(act_fun(self.cnn_act[i]))\n",
        "                    \n",
        "         # layer norm initialization         \n",
        "         self.ln.append(LayerNorm([N_filt,int((current_input-self.cnn_len_filt[i]+1)/self.cnn_max_pool_len[i])]))\n",
        "\n",
        "         self.bn.append(nn.BatchNorm1d(N_filt,int((current_input-self.cnn_len_filt[i]+1)/self.cnn_max_pool_len[i]),momentum=0.05))\n",
        "            \n",
        "\n",
        "         if i==0:\n",
        "          self.conv.append(SincConv_fast(self.cnn_N_filt[0],self.cnn_len_filt[0],self.fs))\n",
        "              \n",
        "         else:\n",
        "          self.conv.append(nn.Conv1d(self.cnn_N_filt[i-1], self.cnn_N_filt[i], self.cnn_len_filt[i]))\n",
        "          \n",
        "         current_input=int((current_input-self.cnn_len_filt[i]+1)/self.cnn_max_pool_len[i])\n",
        "\n",
        "         \n",
        "       self.out_dim=current_input*N_filt\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "       batch=x.shape[0]\n",
        "       seq_len=x.shape[1]\n",
        "       \n",
        "       if bool(self.cnn_use_laynorm_inp):\n",
        "        x=self.ln0((x))\n",
        "        \n",
        "       if bool(self.cnn_use_batchnorm_inp):\n",
        "        x=self.bn0((x))\n",
        "        \n",
        "       x=x.view(batch,1,seq_len)\n",
        "\n",
        "       \n",
        "       for i in range(self.N_cnn_lay):\n",
        "           \n",
        "         if self.cnn_use_laynorm[i]:\n",
        "          if i==0:\n",
        "           x = self.drop[i](self.act[i](self.ln[i](F.max_pool1d(torch.abs(self.conv[i](x)), self.cnn_max_pool_len[i]))))  \n",
        "          else:\n",
        "           x = self.drop[i](self.act[i](self.ln[i](F.max_pool1d(self.conv[i](x), self.cnn_max_pool_len[i]))))   \n",
        "          \n",
        "         if self.cnn_use_batchnorm[i]:\n",
        "          x = self.drop[i](self.act[i](self.bn[i](F.max_pool1d(self.conv[i](x), self.cnn_max_pool_len[i]))))\n",
        "\n",
        "         if self.cnn_use_batchnorm[i]==False and self.cnn_use_laynorm[i]==False:\n",
        "          x = self.drop[i](self.act[i](F.max_pool1d(self.conv[i](x), self.cnn_max_pool_len[i])))\n",
        "\n",
        "       \n",
        "       x = x.view(batch,-1)\n",
        "\n",
        "       return x\n",
        "   "
      ]
    }
  ]
}